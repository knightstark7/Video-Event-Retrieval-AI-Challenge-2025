{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fastapi uvicorn sentence-transformers open-clip-torch qdrant-client \\\n    llama-index llama-index-vector-stores-qdrant llama-index-core pyngrok -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:56:30.980544Z","iopub.execute_input":"2025-08-29T14:56:30.980862Z","iopub.status.idle":"2025-08-29T14:59:05.915003Z","shell.execute_reply.started":"2025-08-29T14:56:30.980836Z","shell.execute_reply":"2025-08-29T14:59:05.912447Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from fastapi import FastAPI, UploadFile, File, Form, Depends, APIRouter\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom qdrant_client import QdrantClient, models\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\nfrom llama_index.core import VectorStoreIndex\nfrom collections import defaultdict\nimport heapq\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\nimport re\nfrom pydantic import PrivateAttr\nfrom llama_index.core.embeddings import BaseEmbedding\nfrom typing import List, Optional\nimport open_clip\nfrom pydantic import BaseModel\nimport json\nfrom PIL import Image\nimport hashlib\nimport io\nimport json\nfrom collections import defaultdict\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:59:05.919165Z","iopub.execute_input":"2025-08-29T14:59:05.919627Z","iopub.status.idle":"2025-08-29T15:00:04.059809Z","shell.execute_reply.started":"2025-08-29T14:59:05.919579Z","shell.execute_reply":"2025-08-29T15:00:04.058031Z"}},"outputs":[{"name":"stderr","text":"2025-08-29 14:59:35.383267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756479575.716340      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756479575.815630      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class CLIPEmbedding(BaseEmbedding):\n    _model = PrivateAttr()\n    _preprocess = PrivateAttr()\n    _tokenizer = PrivateAttr()\n    _device = PrivateAttr()\n\n    def __init__(self, model_name: str = \"ViT-H-14-quickgelu\", device: str = \"cpu\"):\n        super().__init__()\n        self._device = device\n        self._model, _, self._preprocess = open_clip.create_model_and_transforms(\n            model_name=model_name,\n            pretrained=\"dfn5b\",\n            device=self._device\n        )\n        self._tokenizer = open_clip.get_tokenizer(model_name)\n        self._model = self._model.to(self._device).eval()\n\n    def _encode_text(self, text: str) -> List[float]:\n        tokens = self._tokenizer([text]).to(self._device)\n        with torch.no_grad():\n            emb = self._model.encode_text(tokens)\n            emb = emb / emb.norm(dim=-1, keepdim=True) \n        return emb[0].cpu().numpy().tolist()\n\n    def _get_query_embedding(self, query: str) -> List[float]:\n        return self._encode_text(query)\n\n    def _get_text_embedding(self, text: str) -> List[float]:\n        return self._encode_text(text)\n\n    async def _aget_query_embedding(self, query: str) -> List[float]:\n        return self._get_query_embedding(query)\n\n    async def _aget_text_embedding(self, text: str) -> List[float]:\n        return self._get_text_embedding(text)\n\n    def _encode_image(self, image: Image.Image) -> List[float]:\n        image_tensor = self._preprocess(image).unsqueeze(0).to(self._device)\n        with torch.no_grad():\n            emb = self._model.encode_image(image_tensor)\n            emb = emb / emb.norm(dim=-1, keepdim=True)\n        return emb[0].cpu().numpy().tolist()\n        \n    def _get_image_embedding(self, image: Image.Image) -> List[float]:\n            return self._encode_image(image)\n    \n    async def _aget_image_embedding(self, image: Image.Image) -> List[float]:\n        return self._get_image_embedding(image)\n\nclass CaptionEmbedding(BaseEmbedding):\n    _model: SentenceTransformer = PrivateAttr()\n\n    def __init__(self, model_name: str = \"BAAI/bge-small-en\", device: str = \"cpu\", trust_remote_code: bool = False):\n        super().__init__()\n        print(f\"Loading model: {model_name}\")\n        self._model = SentenceTransformer(model_name, device=device, \n                                          trust_remote_code=trust_remote_code)\n        self._model = self._model.eval()\n\n    def _get_query_embedding(self, query: str) -> List[float]:\n        return self._model.encode(query, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=False).tolist()\n\n    def _get_text_embedding(self, text: str) -> List[float]:\n        return self._model.encode(text, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=False).tolist()\n\n    async def _aget_query_embedding(self, query: str) -> List[float]:\n        return self._get_query_embedding(query)\n\n    async def _aget_text_embedding(self, text: str) -> List[float]:\n        return self._get_text_embedding(text)\n\nclass Translator:\n    def __init__(self, model_name: str = \"VietAI/envit5-translation\", device: str = 'cpu'):\n        self.device = device\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)\n\n    def _clean_prefix(self, text: str) -> str:\n        return re.sub(r\"^(en|vi)\\s*:\\s*\", \"\", text.strip(), flags=re.IGNORECASE)\n    \n    def translate(self, text: str, source_lang: str = \"vi\", max_length: int = 128) -> str:\n        content = f\"{source_lang}: {text}\"\n        inputs = self.tokenizer(\n            content, \n            return_tensors=\"pt\", \n            truncation=True, \n            max_length=max_length).to(self.device)\n        with torch.no_grad():\n            outputs = self.model.generate(**inputs, max_length=max_length)\n        decoded = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        return self._clean_prefix(decoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:00:04.060909Z","iopub.execute_input":"2025-08-29T15:00:04.061252Z","iopub.status.idle":"2025-08-29T15:00:04.093343Z","shell.execute_reply.started":"2025-08-29T15:00:04.061227Z","shell.execute_reply":"2025-08-29T15:00:04.091824Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Configuration with Kaggle secrets support\nimport os\n\n# Use Kaggle secrets or fallback to environment variables\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    QDRANT_URL = user_secrets.get_secret(\"QDRANT_URL\")\n    QDRANT_API_KEY = user_secrets.get_secret(\"QDRANT_API_KEY\") \n    NGROK_AUTH_TOKEN = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\n    print(\"âœ… Using Kaggle secrets for configuration\")\nexcept Exception as e:\n    print(f\"âš ï¸  Kaggle secrets not available: {e}\")\n    print(\"ğŸ”§ Falling back to hardcoded values (update these with your credentials)\")\n    # Fallback to hardcoded values - UPDATE THESE WITH YOUR ACTUAL CREDENTIALS\n    QDRANT_URL = \"https://09a6d049-00c4-4b77-8e95-1dcc9ea5df34.eu-west-1-0.aws.cloud.qdrant.io:6333\"\n    QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.-ZPZib9FxehqbTuqxsk7QdVjBQd0LlQEq7dpjF1b4PI\"\n    NGROK_AUTH_TOKEN = \"28k6uZmtZlrKVCzyVQTfjtRSIDd_6GHtfHcwNEojEk9WjkTmv\"\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"ğŸš€ Using device: {DEVICE}\")\n\n# Initialize Qdrant client\nqdrant_client = QdrantClient(\n    url=QDRANT_URL,\n    api_key=QDRANT_API_KEY,\n)\n\nCORS_SETTINGS = {\n    \"allow_origins\": [\"*\"],\n    \"allow_credentials\": True,\n    \"allow_methods\": [\"*\"],\n    \"allow_headers\": [\"*\"],\n}\n\n# Collection names\nCLIP_collection = \"Image\"\nBGE_collection = \"BGE_Caption\"\nGTE_collection = \"GTE_Caption\"\n\nprint(f\"ğŸ“Š Collections: {CLIP_collection}, {BGE_collection}, {GTE_collection}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:04:09.465696Z","iopub.execute_input":"2025-08-29T15:04:09.467004Z","iopub.status.idle":"2025-08-29T15:04:09.882588Z","shell.execute_reply.started":"2025-08-29T15:04:09.466963Z","shell.execute_reply":"2025-08-29T15:04:09.881442Z"}},"outputs":[{"name":"stdout","text":"âš ï¸  Kaggle secrets not available: Unexpected response from the service. Response: {'errors': ['No user secrets exist for kernel id 90800749 and label QDRANT_URL.'], 'error': {'code': 5}, 'wasSuccessful': False}.\nğŸ”§ Falling back to hardcoded values (update these with your credentials)\nğŸš€ Using device: cpu\nğŸ“Š Collections: Image, BGE_Caption, GTE_Caption\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Initialize models\nprint(\"ğŸ”§ Initializing models...\")\n\ntranslator = Translator(device=DEVICE)\nprint(\"âœ… Translator loaded\")\n\nclip_embed_model = CLIPEmbedding(device=DEVICE)\nclip_vector_store = QdrantVectorStore(client=qdrant_client,\n                                      collection_name=CLIP_collection)\nclip_index = VectorStoreIndex.from_vector_store(vector_store=clip_vector_store,\n                                                embed_model=clip_embed_model)\nprint(\"âœ… CLIP model and index loaded\")\n\nbge_embed_model = CaptionEmbedding(model_name=\"AITeamVN/Vietnamese_Embedding_v2\", device=DEVICE)\nbge_vector_store = QdrantVectorStore(client=qdrant_client, \n                                     collection_name=BGE_collection)\nbge_index = VectorStoreIndex.from_vector_store(vector_store=bge_vector_store,\n                                               embed_model=bge_embed_model)\nprint(\"âœ… BGE Vietnamese model loaded\")\n\ngte_embed_model = CaptionEmbedding(model_name=\"dangvantuan/vietnamese-document-embedding\",\n                                   device=DEVICE, trust_remote_code=True)\ngte_vector_store = QdrantVectorStore(client=qdrant_client,\n                                     collection_name=GTE_collection)\ngte_index = VectorStoreIndex.from_vector_store(vector_store=gte_vector_store,\n                                               embed_model=gte_embed_model)\nprint(\"âœ… GTE Document model loaded\")\n\nprint(\"ğŸ‰ All models initialized successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:00:04.619304Z","iopub.execute_input":"2025-08-29T15:00:04.619699Z","iopub.status.idle":"2025-08-29T15:01:48.160263Z","shell.execute_reply.started":"2025-08-29T15:00:04.619674Z","shell.execute_reply":"2025-08-29T15:01:48.159073Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ Initializing models...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a883cf5bc3a4087b4a5b76bd7472304"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e2d3fd55a5d42ae8c32070c53e5570a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f1df27f32d14094866c55fe1e2e4169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70e60bfdb17a4a07bf720d97500f8f22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/721 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dcf867cc7864844b8099ddc531b5058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90cea119301f4114b6abc4f85f6555b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cafa3c8111946fab0c78c8d933e9d5b"}},"metadata":{}},{"name":"stdout","text":"âœ… Translator loaded\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"open_clip_pytorch_model.bin:   0%|          | 0.00/3.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7acf45c800745f9a199814894bf5282"}},"metadata":{}},{"name":"stdout","text":"âœ… CLIP model and index loaded\nLoading model: AITeamVN/Vietnamese_Embedding_v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a946ef1b1ea49efac4c8efed175e250"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cc849d3f8724ed1913f97f0a8e0e781"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5c9045e07914540887fcf4aeee7cbb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f929a0c28da409ca86129da600f834b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf11f9ec553342cd99fb5f9d52c856b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa64cc338814bdb8d69ff9fce481109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"094b4c386a51444e8307ec92a1a57e19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11aec47e7cc448319e7bf55dc80db2ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e9d8a55e9e14e33a14cac5105685e93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917b8acd276d4080890594a963ec3eb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88251048574a4a4b97168f68c9197a41"}},"metadata":{}},{"name":"stdout","text":"âœ… BGE Vietnamese model loaded\nLoading model: dangvantuan/vietnamese-document-embedding\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"787cf305071144bd9f01bcf918ae6c9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b86c758e954436ca18da5d6a6197d61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa95b411cd3142e6b61d15c4dc2b91cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbf212661fcf4d96b9296a57385704a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1048f3e9cbe6492aa929cd2c9b4ccf38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e355711751264d1b9d4c6528085a32a4"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/dangvantuan/Vietnamese_impl:\n- configuration.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aa8d934b2474206a15a4f318a099e03"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/dangvantuan/Vietnamese_impl:\n- modeling.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a899307e4fcc49a5b97d8e895bf7759e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2a4014f01ed4522861dab0a84a8c951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c046e61848244f2ab22f2180cd326b94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3f5ffe7a77a4c44a63b1e63f1cb961d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c2fda5b01341ac89af8a8b2a3d1025"}},"metadata":{}},{"name":"stdout","text":"âœ… GTE Document model loaded\nğŸ‰ All models initialized successfully!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Build frame mappings for temporal search\nprint(\"ğŸ“Š Building frame mappings for temporal search...\")\n\nFRAME_NAMES = []\noffset = None\nbatch_count = 0\n\nwhile True:\n    result, offset = qdrant_client.scroll(\n        collection_name=CLIP_collection,\n        scroll_filter=None,\n        with_payload=True,\n        limit=1000,\n        offset=offset\n    )\n    \n    batch_count += 1\n    print(f\"  Batch {batch_count}: {len(result)} frames\")\n    \n    for point in result:\n        if \"id\" in point.payload:\n            FRAME_NAMES.append(point.payload[\"id\"])\n    \n    if offset is None:\n        break\n\nFRAME_NAMES = sorted(set(FRAME_NAMES))\n\nVIDEO_TO_FRAMES = defaultdict(list)\nfor f in FRAME_NAMES:\n    vid = \"_\".join(f.split(\"_\")[:2]) \n    VIDEO_TO_FRAMES[vid].append(f)\n\nprint(f\"âœ… Loaded {len(FRAME_NAMES)} frame names from {len(VIDEO_TO_FRAMES)} videos\")\nprint(f\"ğŸ“¹ Sample videos: {list(VIDEO_TO_FRAMES.keys())[:5]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:01:48.161180Z","iopub.execute_input":"2025-08-29T15:01:48.161518Z","iopub.status.idle":"2025-08-29T15:01:53.900261Z","shell.execute_reply.started":"2025-08-29T15:01:48.161488Z","shell.execute_reply":"2025-08-29T15:01:53.899017Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Building frame mappings for temporal search...\n  Batch 1: 1000 frames\n  Batch 2: 1000 frames\n  Batch 3: 1000 frames\n  Batch 4: 1000 frames\n  Batch 5: 1000 frames\n  Batch 6: 1000 frames\n  Batch 7: 1000 frames\n  Batch 8: 1000 frames\n  Batch 9: 1000 frames\n  Batch 10: 1000 frames\n  Batch 11: 1000 frames\n  Batch 12: 1000 frames\n  Batch 13: 1000 frames\n  Batch 14: 1000 frames\n  Batch 15: 1000 frames\n  Batch 16: 1000 frames\n  Batch 17: 1000 frames\n  Batch 18: 1000 frames\n  Batch 19: 1000 frames\n  Batch 20: 1000 frames\n  Batch 21: 1000 frames\n  Batch 22: 1000 frames\n  Batch 23: 1000 frames\n  Batch 24: 1000 frames\n  Batch 25: 1000 frames\n  Batch 26: 1000 frames\n  Batch 27: 1000 frames\n  Batch 28: 1000 frames\n  Batch 29: 1000 frames\n  Batch 30: 1000 frames\n  Batch 31: 1000 frames\n  Batch 32: 1000 frames\n  Batch 33: 1000 frames\n  Batch 34: 1000 frames\n  Batch 35: 1000 frames\n  Batch 36: 1000 frames\n  Batch 37: 1000 frames\n  Batch 38: 1000 frames\n  Batch 39: 1000 frames\n  Batch 40: 1000 frames\n  Batch 41: 1000 frames\n  Batch 42: 1000 frames\n  Batch 43: 1000 frames\n  Batch 44: 1000 frames\n  Batch 45: 1000 frames\n  Batch 46: 1000 frames\n  Batch 47: 1000 frames\n  Batch 48: 1000 frames\n  Batch 49: 1000 frames\n  Batch 50: 1000 frames\n  Batch 51: 1000 frames\n  Batch 52: 1000 frames\n  Batch 53: 1000 frames\n  Batch 54: 1000 frames\n  Batch 55: 1000 frames\n  Batch 56: 1000 frames\n  Batch 57: 1000 frames\n  Batch 58: 1000 frames\n  Batch 59: 1000 frames\n  Batch 60: 1000 frames\n  Batch 61: 1000 frames\n  Batch 62: 1000 frames\n  Batch 63: 1000 frames\n  Batch 64: 1000 frames\n  Batch 65: 1000 frames\n  Batch 66: 1000 frames\n  Batch 67: 1000 frames\n  Batch 68: 1000 frames\n  Batch 69: 1000 frames\n  Batch 70: 1000 frames\n  Batch 71: 1000 frames\n  Batch 72: 1000 frames\n  Batch 73: 1000 frames\n  Batch 74: 1000 frames\n  Batch 75: 1000 frames\n  Batch 76: 1000 frames\n  Batch 77: 1000 frames\n  Batch 78: 1000 frames\n  Batch 79: 1000 frames\n  Batch 80: 1000 frames\n  Batch 81: 1000 frames\n  Batch 82: 1000 frames\n  Batch 83: 1000 frames\n  Batch 84: 1000 frames\n  Batch 85: 1000 frames\n  Batch 86: 1000 frames\n  Batch 87: 1000 frames\n  Batch 88: 1000 frames\n  Batch 89: 1000 frames\n  Batch 90: 1000 frames\n  Batch 91: 1000 frames\n  Batch 92: 1000 frames\n  Batch 93: 1000 frames\n  Batch 94: 1000 frames\n  Batch 95: 1000 frames\n  Batch 96: 1000 frames\n  Batch 97: 545 frames\nâœ… Loaded 96545 frame names from 866 videos\nğŸ“¹ Sample videos: ['L21_V001', 'L21_V002', 'L21_V003', 'L21_V005', 'L21_V006']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def retrieve(query: str, topK: int, frame_ids: Optional[List] = None,\n             mode: str = \"clip\", caption_mode: str = \"bge\"):\n    \"\"\"\n    Universal retrieve function with frame filtering support\n    \"\"\"\n    if mode == \"clip\":\n        embed_model = clip_embed_model\n        index = clip_index\n        collection_name = CLIP_collection\n        query_text = translator.translate(query, source_lang=\"vi\")\n    elif mode == \"vintern\":\n        if caption_mode == \"bge\":\n            embed_model = bge_embed_model\n            index = bge_index\n            collection_name = BGE_collection\n            query_text = query\n        else:  # gte\n            embed_model = gte_embed_model\n            index = gte_index\n            collection_name = GTE_collection\n            query_text = query\n        \n    if frame_ids: \n        # Direct query with frame filtering\n        vector_query = embed_model._get_text_embedding(query_text)\n        nodes = qdrant_client.query_points(\n            collection_name=collection_name,\n            query=vector_query,\n            limit=topK,\n            with_payload=True,\n            query_filter=models.Filter(must=[\n                models.FieldCondition(\n                    key=\"id\",\n                    match=models.MatchAny(any=frame_ids)\n                )\n            ])\n        ).points\n        results = [\n            {\"id\": node.payload[\"id\"].strip(), \"score\": node.score}\n            for node in nodes\n        ]\n    else:\n        # Use index for full search\n        retriever = index.as_retriever(similarity_top_k=topK)\n        nodes = retriever.retrieve(query_text)\n        results = [\n            {\"id\": node.metadata.get(\"id\", \"\").strip(), \"score\": node.score}\n            for node in nodes\n        ]\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:01:53.901521Z","iopub.execute_input":"2025-08-29T15:01:53.901839Z","iopub.status.idle":"2025-08-29T15:01:53.916415Z","shell.execute_reply.started":"2025-08-29T15:01:53.901815Z","shell.execute_reply":"2025-08-29T15:01:53.915210Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def retrieve_frame(query: str, topK: int, mode: str = \"hybrid\", caption_mode: str = \"bge\",\n                   alpha: float = 0.5, frame_ids: Optional[List] = None):\n    \"\"\"\n    Enhanced retrieve_frame with caption mode support\n    \"\"\"\n    if mode == \"clip\":\n        clip_nodes = retrieve(query, topK, frame_ids, \"clip\")\n        results = [\n            {\"image\": node[\"id\"], \"caption\": f\"{node['id']} | Score: {node['score']:.2f}\"}\n            for node in clip_nodes\n        ]\n        return results\n    \n    elif mode == \"vintern\":\n        caption_nodes = retrieve(query, topK, frame_ids, \"vintern\", caption_mode)\n        results = [\n            {\"image\": node[\"id\"], \"caption\": f\"{node['id']} | Score: {node['score']:.2f}\"}\n            for node in caption_nodes\n        ]\n        return results\n    \n    else:  # hybrid mode\n        clip_nodes = retrieve(query, topK, frame_ids, \"clip\")\n        caption_nodes = retrieve(query, topK, frame_ids, \"vintern\", caption_mode)\n        \n        combined_scores = defaultdict(float)\n        for node in caption_nodes:\n            combined_scores[node[\"id\"]] += node[\"score\"] * alpha\n\n        for node in clip_nodes:\n            combined_scores[node[\"id\"]] += node[\"score\"] * (1 - alpha)\n\n        top_results = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:topK]\n\n        return [\n            {\"image\": video_id.strip(), \"caption\": f\"{video_id} | Score: {score:.2f}\"}\n            for video_id, score in top_results\n        ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:01:53.918169Z","iopub.execute_input":"2025-08-29T15:01:53.918603Z","iopub.status.idle":"2025-08-29T15:01:58.562195Z","shell.execute_reply.started":"2025-08-29T15:01:53.918572Z","shell.execute_reply":"2025-08-29T15:01:58.560159Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def retrieve_from_image(contents: bytes, topK: int):\n    \"\"\"\n    Image-based search using CLIP embeddings\n    \"\"\"\n    image = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n    vector_query = clip_embed_model._get_image_embedding(image)\n\n    clip_nodes = qdrant_client.query_points(\n        collection_name=CLIP_collection,\n        query=vector_query,\n        limit=topK,\n        with_payload=True\n    ).points\n\n    results = [\n        {\n            \"image\": node.payload.get(\"id\", \"\").strip(),\n            \"caption\": f\"{node.payload.get('id', '')} | Score: {node.score:.2f}\"\n        }\n        for node in clip_nodes\n    ]\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:01:58.564190Z","iopub.execute_input":"2025-08-29T15:01:58.566319Z","iopub.status.idle":"2025-08-29T15:01:58.604824Z","shell.execute_reply.started":"2025-08-29T15:01:58.566265Z","shell.execute_reply":"2025-08-29T15:01:58.603151Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def temporal_search(events: List[str], topK: int = 100, \n                    mode: str = \"hybrid\", caption_mode: str = \"bge\",\n                    alpha: float = 0.5):\n    \"\"\"\n    Temporal search for TRAKE mode - progressive filtering through video sequences\n    \"\"\"\n    frame_ids = None\n    final_results = []  \n    \n    print(f\"ğŸ” Starting temporal search with {len(events)} events...\")\n\n    for i, event in enumerate(events):\n        print(f\"  Event {i+1}: {event[:50]}...\")\n        \n        results = retrieve_frame(query=event, topK=topK, mode=mode, \n                                 caption_mode=caption_mode, alpha=alpha, frame_ids=frame_ids)\n        final_results.append(results)\n        \n        # Extract video IDs from current results to narrow search space\n        video_ids = {\"_\".join(item['image'].split(\"_\")[:2]) for item in results}\n        print(f\"    â†’ Found {len(results)} results from {len(video_ids)} videos\")\n\n        # Update frame_ids to frames from videos in current results\n        frame_ids = [f for vid in video_ids for f in VIDEO_TO_FRAMES[vid]]\n        print(f\"    â†’ Narrowed search space to {len(frame_ids)} frames\")\n    \n    print(f\"âœ… Temporal search completed!\")\n    return final_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:01:58.606528Z","iopub.execute_input":"2025-08-29T15:01:58.606983Z","iopub.status.idle":"2025-08-29T15:01:58.646014Z","shell.execute_reply.started":"2025-08-29T15:01:58.606950Z","shell.execute_reply":"2025-08-29T15:01:58.644213Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# FastAPI Application\napp = FastAPI(title=\"Video Event Retrieval API v2.0\", \n              description=\"Enhanced multimodal search with temporal capabilities\")\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=CORS_SETTINGS[\"allow_origins\"],\n    allow_credentials=CORS_SETTINGS[\"allow_credentials\"],\n    allow_methods=CORS_SETTINGS[\"allow_methods\"],\n    allow_headers=CORS_SETTINGS[\"allow_headers\"],\n)\n\nrouter = APIRouter()\n\n@router.post(\"/search\")\nasync def api_search(\n    query: Optional[str] = Form(None),\n    topK: int = Form(...),\n    mode: str = Form(\"hybrid\"),\n    caption_mode: str = Form(\"bge\"),\n    alpha: float = Form(0.5),\n    file: UploadFile = File(None)\n):\n    \"\"\"\n    Enhanced search API with caption mode support\n    - mode: hybrid, clip, vintern, image\n    - caption_mode: bge, gte (for vintern and hybrid modes)\n    - alpha: text/visual balance for hybrid mode (0.1-0.9)\n    \"\"\"\n    start_time = time.time()\n    \n    try:\n        if mode == \"image\":\n            if file is None:\n                return {\"error\": \"No file uploaded for image mode\"}\n            contents = await file.read()\n            results = retrieve_from_image(contents=contents, topK=topK)\n            search_info = f\"IMAGE search\"\n        else:\n            if query is None or query.strip() == \"\":\n                return {\"error\": \"No query provided for text mode\"}\n            results = retrieve_frame(query=query, topK=topK, mode=mode, \n                                    caption_mode=caption_mode, alpha=alpha)\n            search_info = f\"{mode.upper()} mode with {caption_mode.upper()} model\"\n        \n        duration = time.time() - start_time\n        \n        return {\n            \"results\": results,\n            \"search_info\": {\n                \"mode\": mode,\n                \"caption_mode\": caption_mode if mode in [\"hybrid\", \"vintern\"] else None,\n                \"alpha\": alpha if mode == \"hybrid\" else None,\n                \"duration\": round(duration, 3),\n                \"count\": len(results),\n                \"description\": search_info\n            }\n        }\n    except Exception as e:\n        return {\"error\": f\"Search failed: {str(e)}\"}\n\n@router.post(\"/temporal_search\")\nasync def api_temporal_search(\n    events: str = Form(...),  # JSON string of event list\n    topK: int = Form(100),\n    mode: str = Form(\"hybrid\"),\n    caption_mode: str = Form(\"bge\"),\n    alpha: float = Form(0.5)\n):\n    \"\"\"\n    Temporal search API for TRAKE mode\n    - events: JSON array of sequential event descriptions\n    - Returns progressive results for each event\n    \"\"\"\n    start_time = time.time()\n    \n    try:\n        events_list = json.loads(events)\n        if not isinstance(events_list, list) or len(events_list) == 0:\n            return {\"error\": \"Events must be a non-empty list\"}\n        \n        # Filter out empty events\n        valid_events = [e.strip() for e in events_list if e.strip()]\n        if len(valid_events) == 0:\n            return {\"error\": \"No valid events provided\"}\n        \n        results = temporal_search(events=valid_events, topK=topK, mode=mode,\n                                 caption_mode=caption_mode, alpha=alpha)\n        \n        duration = time.time() - start_time\n        \n        return {\n            \"results\": results,\n            \"search_info\": {\n                \"mode\": mode,\n                \"caption_mode\": caption_mode,\n                \"alpha\": alpha if mode == \"hybrid\" else None,\n                \"duration\": round(duration, 3),\n                \"events_processed\": len(valid_events),\n                \"final_count\": len(results[-1]) if results else 0,\n                \"description\": f\"Temporal search through {len(valid_events)} events\"\n            }\n        }\n    except json.JSONDecodeError:\n        return {\"error\": \"Invalid JSON format for events\"}\n    except Exception as e:\n        return {\"error\": f\"Temporal search failed: {str(e)}\"}\n\n@router.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint\"\"\"\n    return {\n        \"status\": \"healthy\",\n        \"device\": DEVICE,\n        \"models_loaded\": {\n            \"clip\": clip_embed_model is not None,\n            \"bge\": bge_embed_model is not None,\n            \"gte\": gte_embed_model is not None,\n            \"translator\": translator is not None\n        },\n        \"collections\": {\n            \"clip\": CLIP_collection,\n            \"bge\": BGE_collection,\n            \"gte\": GTE_collection\n        },\n        \"frame_count\": len(FRAME_NAMES),\n        \"video_count\": len(VIDEO_TO_FRAMES)\n    }\n\napp.include_router(router)\nprint(\"âœ… FastAPI application configured\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:01:58.647347Z","iopub.execute_input":"2025-08-29T15:01:58.648233Z","iopub.status.idle":"2025-08-29T15:01:58.702187Z","shell.execute_reply.started":"2025-08-29T15:01:58.648160Z","shell.execute_reply":"2025-08-29T15:01:58.700267Z"}},"outputs":[{"name":"stdout","text":"âœ… FastAPI application configured\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Server setup with ngrok\nimport os, time, threading, socket\nfrom pyngrok import ngrok\nimport uvicorn\n\nPORT = 8000\nHOST = \"0.0.0.0\"\n\n# Set ngrok auth token\nif NGROK_AUTH_TOKEN and NGROK_AUTH_TOKEN != \"YOUR_NGROK_TOKEN_HERE\":\n    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n    print(\"âœ… Ngrok auth token set\")\nelse:\n    print(\"âš ï¸  NGROK_AUTH_TOKEN not configured. Please update with your token.\")\n    print(\"   Get your token from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n\ndef is_port_in_use(port: int, host=\"127.0.0.1\") -> bool:\n    \"\"\"Check if a local TCP port is already in use.\"\"\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        return s.connect_ex((host, port)) == 0\n\ndef run_server():\n    \"\"\"Run FastAPI server in background thread\"\"\"\n    uvicorn.run(app, host=HOST, port=PORT, log_level=\"info\")\n\n# Start server only if not already running\nif not is_port_in_use(PORT):\n    print(f\"ğŸš€ Starting FastAPI server on {HOST}:{PORT}\")\n    server_thread = threading.Thread(target=run_server, daemon=True)\n    server_thread.start()\n    time.sleep(3)  # Wait for server startup\n    print(\"âœ… Server started successfully\")\nelse:\n    print(f\"ğŸ” Server already running on http://localhost:{PORT}\")\n\n# Setup ngrok tunnel\ntry:\n    # Clean up existing tunnels\n    for t in ngrok.get_tunnels():\n        addr = (t.config or {}).get(\"addr\", \"\")\n        if str(PORT) in addr:\n            try:\n                ngrok.disconnect(t.public_url)\n            except Exception:\n                pass\n\n    # Kill all tunnels if too many\n    if len(ngrok.get_tunnels()) >= 3:\n        ngrok.kill()\n\n    # Create new tunnel\n    tunnel = ngrok.connect(addr=PORT, proto=\"http\", bind_tls=True)\n    PUBLIC_URL = tunnel.public_url\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸŒ BACKEND READY!\")\n    print(f\"ğŸ“¡ Public URL: {PUBLIC_URL}\")\n    print(f\"ğŸ“– API Docs: {PUBLIC_URL}/docs\")\n    print(f\"ğŸ¥ Health Check: {PUBLIC_URL}/health\")\n    print(f\"ğŸ’» Local URL: http://localhost:{PORT}\")\n    print(\"\\nğŸ¯ COPY THE PUBLIC URL TO YOUR FRONTEND!\")\n    print(\"=\"*60)\n\n    # Save to global for later use\n    globals()[\"PUBLIC_URL\"] = PUBLIC_URL\n\nexcept Exception as e:\n    print(f\"âŒ Ngrok tunnel failed: {e}\")\n    print(f\"ğŸ”§ Server still available locally: http://localhost:{PORT}\")\n    print(\"ğŸ’¡ Try restarting the kernel or checking your ngrok auth token\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:04:31.123959Z","iopub.execute_input":"2025-08-29T15:04:31.124330Z","iopub.status.idle":"2025-08-29T15:04:31.783554Z","shell.execute_reply.started":"2025-08-29T15:04:31.124307Z","shell.execute_reply":"2025-08-29T15:04:31.782084Z"}},"outputs":[{"name":"stdout","text":"âœ… Ngrok auth token set\nğŸ” Server already running on http://localhost:8000\n\n============================================================\nğŸŒ BACKEND READY!\nğŸ“¡ Public URL: https://d6dd4a9b06c5.ngrok-free.app\nğŸ“– API Docs: https://d6dd4a9b06c5.ngrok-free.app/docs\nğŸ¥ Health Check: https://d6dd4a9b06c5.ngrok-free.app/health\nğŸ’» Local URL: http://localhost:8000\n\nğŸ¯ COPY THE PUBLIC URL TO YOUR FRONTEND!\n============================================================\nINFO:     14.234.51.109:0 - \"OPTIONS /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"OPTIONS /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 10 results from 4 videos\n    â†’ Narrowed search space to 414 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 10 results from 3 videos\n    â†’ Narrowed search space to 301 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"GET / HTTP/1.1\" 404 Not Found\nINFO:     14.234.51.109:0 - \"GET / HTTP/1.1\" 404 Not Found\nINFO:     14.234.51.109:0 - \"GET / HTTP/1.1\" 404 Not Found\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 100 results from 78 videos\n    â†’ Narrowed search space to 8098 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 100 results from 48 videos\n    â†’ Narrowed search space to 5010 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 100 results from 17 videos\n    â†’ Narrowed search space to 1579 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 10 results from 4 videos\n    â†’ Narrowed search space to 414 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 10 results from 3 videos\n    â†’ Narrowed search space to 301 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"OPTIONS /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"OPTIONS /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 10 results from 4 videos\n    â†’ Narrowed search space to 414 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 10 results from 3 videos\n    â†’ Narrowed search space to 301 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Test the enhanced API\nimport requests\n\ndef test_api_endpoints(use_public_url=True):\n    \"\"\"Test all API endpoints with the new features\"\"\"\n    \n    if use_public_url and 'PUBLIC_URL' in globals():\n        base_url = globals()['PUBLIC_URL']\n        print(f\"ğŸ”— Testing public URL: {base_url}\")\n    else:\n        base_url = \"http://localhost:8000\"\n        print(f\"ğŸ”— Testing local URL: {base_url}\")\n    \n    # Test health endpoint\n    print(\"\\n1. ğŸ¥ Testing health endpoint...\")\n    try:\n        response = requests.get(f\"{base_url}/health\", timeout=10)\n        if response.status_code == 200:\n            health = response.json()\n            print(f\"   âœ… Health check passed\")\n            print(f\"   ğŸ“Š {health['frame_count']} frames from {health['video_count']} videos\")\n            print(f\"   ğŸ¤– Models: {health['models_loaded']}\")\n        else:\n            print(f\"   âŒ Health check failed: {response.status_code}\")\n    except Exception as e:\n        print(f\"   âŒ Health check error: {e}\")\n        return\n    \n    # Test search with BGE\n    print(\"\\n2. ğŸ” Testing hybrid search with BGE...\")\n    test_search(base_url, \"ngÆ°á»i Ä‘ang náº¥u Äƒn\", mode=\"hybrid\", caption_mode=\"bge\")\n    \n    # Test search with GTE\n    print(\"\\n3. ğŸ” Testing hybrid search with GTE...\")\n    test_search(base_url, \"ngÆ°á»i Ä‘ang náº¥u Äƒn\", mode=\"hybrid\", caption_mode=\"gte\")\n    \n    # Test vintern only with GTE\n    print(\"\\n4. ğŸ“ Testing vintern search with GTE...\")\n    test_search(base_url, \"cáº£nh Ä‘áº¹p thiÃªn nhiÃªn\", mode=\"vintern\", caption_mode=\"gte\")\n    \n    # Test temporal search\n    print(\"\\n5. â° Testing temporal search...\")\n    test_temporal_search(base_url, [\n        \"Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘em nÆ°á»›ng trÃªn cháº£o. HÃ£y láº¥y khoáº£nh kháº¯c chiáº¿c dao cáº¯t qua hoÃ n toÃ n chiáº¿c bÃ¡nh.\",\n        \"Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, trong quÃ¡ trÃ¬nh nÃ y ngÆ°á»i Ä‘áº§u báº¿p láº­t nhá»¯ng miáº¿ng thá»‹t Ä‘á»ƒ ráº¯c bá»™t Ä‘á»u hai máº·t. HÃ£y láº¥y khoáº£nh kháº¯c Ä‘áº§u tiÃªn ngÆ°á»i Ä‘áº§u báº¿p nÃ y buÃ´ng tay khá»i miáº¿ng thá»‹t sau khi láº­t miáº¿ng thá»‹t Ä‘áº§u tiÃªn.\",\n        \"CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i bÆ¡ (3 ngang 1 dá»c theo chiá»u cá»§a camera). HÃ£y láº¥y khoáº£nh kháº¯c Ä‘áº§u tiÃªn ngÆ°á»i Ä‘áº§u báº¿p cáº§m vÃ o cháº£o Ä‘á»ƒ nháº¥c lÃªn Ä‘áº£o bÆ¡ Ä‘á»u xung quanh\"\n    ])\n\ndef test_search(base_url, query, mode=\"hybrid\", caption_mode=\"bge\", topK=5):\n    \"\"\"Test search endpoint\"\"\"\n    try:\n        data = {\n            \"query\": query,\n            \"topK\": topK,\n            \"mode\": mode,\n            \"caption_mode\": caption_mode,\n            \"alpha\": 0.6\n        }\n        \n        response = requests.post(f\"{base_url}/search\", data=data, timeout=30)\n        \n        if response.status_code == 200:\n            result = response.json()\n            search_info = result.get(\"search_info\", {})\n            print(f\"   âœ… Search successful: {search_info.get('description')}\")\n            print(f\"   â±ï¸ Duration: {search_info.get('duration')}s\")\n            print(f\"   ğŸ“Š Results: {len(result['results'])}\")\n            \n            # Show top results\n            for i, res in enumerate(result['results'][:3]):\n                print(f\"      {i+1}. {res['caption']}\")\n        else:\n            print(f\"   âŒ Search failed: {response.status_code} - {response.text}\")\n    except Exception as e:\n        print(f\"   âŒ Search error: {e}\")\n\ndef test_temporal_search(base_url, events, topK=20):\n    \"\"\"Test temporal search endpoint\"\"\"\n    try:\n        data = {\n            \"events\": json.dumps(events),\n            \"topK\": topK,\n            \"mode\": \"hybrid\",\n            \"caption_mode\": \"gte\",\n            \"alpha\": 0.7\n        }\n        \n        response = requests.post(f\"{base_url}/temporal_search\", data=data, timeout=60)\n        \n        if response.status_code == 200:\n            result = response.json()\n            search_info = result.get(\"search_info\", {})\n            print(f\"   âœ… Temporal search successful: {search_info.get('description')}\")\n            print(f\"   â±ï¸ Duration: {search_info.get('duration')}s\")\n            print(f\"   ğŸ“Š Events processed: {search_info.get('events_processed')}\")\n            print(f\"   ğŸ¯ Final results: {search_info.get('final_count')}\")\n            \n            # Show progression\n            for i, event_results in enumerate(result['results']):\n                print(f\"      Event {i+1}: {len(event_results)} results\")\n                for j, res in enumerate(event_results[:2]):\n                    print(f\"        â†’ {res['caption']}\")\n        else:\n            print(f\"   âŒ Temporal search failed: {response.status_code} - {response.text}\")\n    except Exception as e:\n        print(f\"   âŒ Temporal search error: {e}\")\n\n# Run tests\nprint(\"ğŸ§ª Testing Enhanced API...\")\ntest_api_endpoints()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:53:34.815578Z","iopub.execute_input":"2025-08-29T15:53:34.816496Z","iopub.status.idle":"2025-08-29T15:53:49.563322Z","shell.execute_reply.started":"2025-08-29T15:53:34.816456Z","shell.execute_reply":"2025-08-29T15:53:49.562154Z"}},"outputs":[{"name":"stdout","text":"ğŸ§ª Testing Enhanced API...\nğŸ”— Testing public URL: https://d6dd4a9b06c5.ngrok-free.app\n\n1. ğŸ¥ Testing health endpoint...\nINFO:     34.91.46.191:0 - \"GET /health HTTP/1.1\" 200 OK\n   âœ… Health check passed\n   ğŸ“Š 96545 frames from 866 videos\n   ğŸ¤– Models: {'clip': True, 'bge': True, 'gte': True, 'translator': True}\n\n2. ğŸ” Testing hybrid search with BGE...\nINFO:     34.91.46.191:0 - \"POST /search HTTP/1.1\" 200 OK\n   âœ… Search successful: HYBRID mode with BGE model\n   â±ï¸ Duration: 1.57s\n   ğŸ“Š Results: 5\n      1. L26_V272_5537 | Score: 0.42\n      2. L26_V452_4878 | Score: 0.42\n      3. L26_V339_5215 | Score: 0.41\n\n3. ğŸ” Testing hybrid search with GTE...\nINFO:     34.91.46.191:0 - \"POST /search HTTP/1.1\" 200 OK\n   âœ… Search successful: HYBRID mode with GTE model\n   â±ï¸ Duration: 1.286s\n   ğŸ“Š Results: 5\n      1. L27_V003_6294 | Score: 0.38\n      2. L26_V367_5958 | Score: 0.38\n      3. L26_V484_3594 | Score: 0.37\n\n4. ğŸ“ Testing vintern search with GTE...\nINFO:     34.91.46.191:0 - \"POST /search HTTP/1.1\" 200 OK\n   âœ… Search successful: VINTERN mode with GTE model\n   â±ï¸ Duration: 0.113s\n   ğŸ“Š Results: 5\n      1. L27_V008_12041 | Score: 0.68\n      2. L28_V016_5421 | Score: 0.66\n      3. L28_V018_13549 | Score: 0.63\n\n5. â° Testing temporal search...\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 20 results from 18 videos\n    â†’ Narrowed search space to 1814 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 20 results from 7 videos\n    â†’ Narrowed search space to 732 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 20 results from 4 videos\n    â†’ Narrowed search space to 433 frames\nâœ… Temporal search completed!\nINFO:     34.91.46.191:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\n   âœ… Temporal search successful: Temporal search through 3 events\n   â±ï¸ Duration: 9.977s\n   ğŸ“Š Events processed: 3\n   ğŸ¯ Final results: 20\n      Event 1: 20 results\n        â†’ L26_V289_1948 | Score: 0.61\n        â†’ L26_V399_5336 | Score: 0.58\n      Event 2: 20 results\n        â†’ L26_V399_2790 | Score: 0.43\n        â†’ L26_V251_2204 | Score: 0.43\n      Event 3: 20 results\n        â†’ L26_V247_4538 | Score: 0.52\n        â†’ L26_V399_4814 | Score: 0.49\nINFO:     14.234.51.109:0 - \"OPTIONS /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"OPTIONS /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 1 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"POST /search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 10 results from 4 videos\n    â†’ Narrowed search space to 414 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 10 results from 3 videos\n    â†’ Narrowed search space to 301 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 10 results from 4 videos\n    â†’ Narrowed search space to 414 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 10 results from 3 videos\n    â†’ Narrowed search space to 301 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"OPTIONS /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 100 results from 78 videos\n    â†’ Narrowed search space to 8098 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 100 results from 48 videos\n    â†’ Narrowed search space to 5010 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 100 results from 17 videos\n    â†’ Narrowed search space to 1579 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nINFO:     14.234.51.109:0 - \"OPTIONS /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 10 results from 4 videos\n    â†’ Narrowed search space to 414 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 10 results from 3 videos\n    â†’ Narrowed search space to 301 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\nğŸ” Starting temporal search with 3 events...\n  Event 1: Má»™t ngÆ°á»i  Ä‘ang cáº¯t Ä‘Ã´i á»• bÃ¡nh mÃ¬ cÃ³ ráº¯c mÃ¨ rá»“i Ä‘e...\n    â†’ Found 10 results from 10 videos\n    â†’ Narrowed search space to 1068 frames\n  Event 2: Sau Ä‘Ã³ ngÆ°á»i nÃ y ráº¯c bá»™t lÃªn nhá»¯ng miáº¿ng thá»‹t, tro...\n    â†’ Found 10 results from 4 videos\n    â†’ Narrowed search space to 414 frames\n  Event 3: CÃ¡c miáº¿ng thá»‹t sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘em Ä‘i Ã¡p cháº£o cÃ¹ng vá»›i...\n    â†’ Found 10 results from 3 videos\n    â†’ Narrowed search space to 301 frames\nâœ… Temporal search completed!\nINFO:     14.234.51.109:0 - \"POST /temporal_search HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}