{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50abf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from pydantic import PrivateAttr\n",
    "from typing import List\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "from llama_index.core.schema import TextNode\n",
    "import h5py\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e33699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPEmbedding(BaseEmbedding):\n",
    "    _model = PrivateAttr()\n",
    "    _preprocess = PrivateAttr()\n",
    "    _tokenizer = PrivateAttr()\n",
    "    _device = PrivateAttr()\n",
    "\n",
    "    def __init__(self, model_name: str = \"hf-hub:apple/DFN2B-CLIP-ViT-B-16\", device: str = \"cpu\"):\n",
    "        super().__init__()\n",
    "        self._device = device\n",
    "        self._model, self._preprocess = create_model_from_pretrained(model_name)\n",
    "        self._tokenizer = get_tokenizer(\"ViT-B-16\")\n",
    "        self._model = self._model.to(self._device).eval()\n",
    "\n",
    "    def _encode_text(self, text: str) -> List[float]:\n",
    "        tokens = self._tokenizer([text]).to(self._device)\n",
    "        with torch.no_grad():\n",
    "            emb = self._model.encode_text(tokens) \n",
    "        return emb[0].cpu().numpy().tolist()\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._encode_text(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._encode_text(text)\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embed_model = CLIPEmbedding(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25caed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://09a6d049-00c4-4b77-8e95-1dcc9ea5df34.eu-west-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.-ZPZib9FxehqbTuqxsk7QdVjBQd0LlQEq7dpjF1b4PI\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a2b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "with h5py.File(\"features/frame_features.hdf5\", \"r\") as fs:\n",
    "    for key in fs.keys():\n",
    "        embeddings = fs[key][()]\n",
    "        median_id = len(embeddings) // 2\n",
    "\n",
    "        node = TextNode(\n",
    "            text=f\"Frame {key}\",\n",
    "            metadata={\"id\": key},\n",
    "            embedding=embeddings[median_id].tolist()\n",
    "        )\n",
    "        nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e7b3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efde7e56519e44b28e2691610dec1950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collection_name = \"image\"\n",
    "vector_store = QdrantVectorStore(client=qdrant_client, collection_name=collection_name)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context, embed_model=embed_model, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3af6d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Káº¿t quáº£ 1:\n",
      "Score: 0.2782\n",
      "Metadata: {'id': '0bSz70pYAP0_5_15'}\n",
      "Ná»™i dung: Frame 0bSz70pYAP0_5_15\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 2:\n",
      "Score: 0.2406\n",
      "Metadata: {'id': 'VxM96IYzw0Q_2_15'}\n",
      "Ná»™i dung: Frame VxM96IYzw0Q_2_15\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 3:\n",
      "Score: 0.2397\n",
      "Metadata: {'id': 'ZbzDGXEwtGc_6_15'}\n",
      "Ná»™i dung: Frame ZbzDGXEwtGc_6_15\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 4:\n",
      "Score: 0.2222\n",
      "Metadata: {'id': 'Eamd2wMKixs_48_72'}\n",
      "Ná»™i dung: Frame Eamd2wMKixs_48_72\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 5:\n",
      "Score: 0.2221\n",
      "Metadata: {'id': 'DN7jwyL1Xgg_1_19'}\n",
      "Ná»™i dung: Frame DN7jwyL1Xgg_1_19\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 6:\n",
      "Score: 0.2179\n",
      "Metadata: {'id': '4MjTb5A68VA_111_118'}\n",
      "Ná»™i dung: Frame 4MjTb5A68VA_111_118\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 7:\n",
      "Score: 0.2141\n",
      "Metadata: {'id': 'vz71JKcpeUU_0_10'}\n",
      "Ná»™i dung: Frame vz71JKcpeUU_0_10\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 8:\n",
      "Score: 0.2116\n",
      "Metadata: {'id': '3chNlP5TeO8_0_10'}\n",
      "Ná»™i dung: Frame 3chNlP5TeO8_0_10\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 9:\n",
      "Score: 0.2099\n",
      "Metadata: {'id': 'Gn4Iv5ARIXc_37_40'}\n",
      "Ná»™i dung: Frame Gn4Iv5ARIXc_37_40\n",
      "\n",
      "ðŸ”Ž Káº¿t quáº£ 10:\n",
      "Score: 0.2078\n",
      "Metadata: {'id': '5W02895vT8c_312_322'}\n",
      "Ná»™i dung: Frame 5W02895vT8c_312_322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(client=qdrant_client, collection_name=collection_name)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store, embed_model=embed_model)\n",
    "retriever = index.as_retriever(similarity_top_k=10)\n",
    "query = \"a plane flying in the sky\"\n",
    "nodes = retriever.retrieve(query)\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"ðŸ”Ž Káº¿t quáº£ {i+1}:\")\n",
    "    print(f\"Score: {node.score:.4f}\")\n",
    "    print(\"Metadata:\", node.metadata)\n",
    "    print(f\"Ná»™i dung: {node.get_content()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
