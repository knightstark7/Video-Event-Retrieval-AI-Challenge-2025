{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T16:00:49.347261Z",
     "iopub.status.busy": "2025-08-15T16:00:49.346651Z",
     "iopub.status.idle": "2025-08-15T16:02:13.713444Z",
     "shell.execute_reply": "2025-08-15T16:02:13.712551Z",
     "shell.execute_reply.started": "2025-08-15T16:00:49.347228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T17:13:57.101833Z",
     "iopub.status.busy": "2025-08-15T17:13:57.101529Z",
     "iopub.status.idle": "2025-08-15T17:13:57.110508Z",
     "shell.execute_reply": "2025-08-15T17:13:57.109908Z",
     "shell.execute_reply.started": "2025-08-15T17:13:57.101809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile infer.py\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch import autocast, inference_mode\n",
    "# from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from functools import lru_cache\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "IMAGENET_STD = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_target_ratios(min_num, max_num):\n",
    "    ratios = [(i, j) for n in range(min_num, max_num + 1)\n",
    "              for i in range(1, n + 1)\n",
    "              for j in range(1, n + 1)\n",
    "              if min_num <= i * j <= max_num]\n",
    "    return sorted(ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff or (\n",
    "            ratio_diff == best_ratio_diff and area > 0.5 * image_size * image_size * ratio[0] * ratio[1]\n",
    "        ):\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess_cv2(image_np, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_height, orig_width = image_np.shape[:2]\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    target_ratios = get_target_ratios(min_num, max_num)\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size\n",
    "    )\n",
    "\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    cols = target_width // image_size\n",
    "    rows = target_height // image_size\n",
    "\n",
    "    resized = cv2.resize(image_np, (target_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    processed = [\n",
    "        resized[r * image_size:(r + 1) * image_size,\n",
    "                c * image_size:(c + 1) * image_size, :]\n",
    "        for r in range(rows) for c in range(cols)\n",
    "    ]\n",
    "\n",
    "    if use_thumbnail and len(processed) != 1:\n",
    "        thumb = cv2.resize(image_np, (image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "        processed.append(thumb)\n",
    "\n",
    "    return processed\n",
    "\n",
    "def to_tensor_and_normalize(img_list):\n",
    "    tensors = []\n",
    "    for img in img_list:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        t = torch.from_numpy(img_rgb).permute(2, 0, 1).float() / 255.0\n",
    "        t = (t - IMAGENET_MEAN) / IMAGENET_STD\n",
    "        tensors.append(t)\n",
    "    return torch.stack(tensors)\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image_np = cv2.imread(image_file)  # BGR\n",
    "    images = dynamic_preprocess_cv2(image_np, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = to_tensor_and_normalize(images)\n",
    "    return pixel_values\n",
    "\n",
    "def workers(rank, all_chunks, batch_size, question, generation_config):\n",
    "    \"\"\"Inference worker for one GPU.\"\"\"\n",
    "    paths = all_chunks[rank]\n",
    "    torch.set_grad_enabled(False)\n",
    "    torch.cuda.set_device(rank)\n",
    "    device = f\"cuda:{rank}\"\n",
    "    print(f\"Process {rank} using {device}\")\n",
    "\n",
    "    model = AutoModel.from_pretrained(\n",
    "        \"5CD-AI/Vintern-1B-v3_5\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True,\n",
    "        use_flash_attn=True\n",
    "    ).eval().to(device)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"5CD-AI/Vintern-1B-v3_5\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    temp_csv = f\"inference_results_{rank}.csv\"\n",
    "    processed_local = set()\n",
    "\n",
    "    # Load already processed frames for this GPU's temp CSV\n",
    "    if os.path.exists(temp_csv):\n",
    "        with open(temp_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader, None)\n",
    "            for row in reader:\n",
    "                if row:\n",
    "                    processed_local.add(row[0])\n",
    "\n",
    "    # Filter out processed frames from this worker's list\n",
    "    paths = [p for p in paths if os.path.basename(p) not in processed_local]\n",
    "    print(f\"GPU{rank}: {len(paths)} images left after skipping {len(processed_local)} already processed locally.\")\n",
    "\n",
    "    # Open CSV in append mode\n",
    "    write_header = not os.path.exists(temp_csv)\n",
    "    with open(temp_csv, \"a\", newline=\"\", encoding=\"utf-8\", buffering=1) as f:\n",
    "        writer = csv.writer(f)\n",
    "        if write_header:\n",
    "            writer.writerow([\"frame_name\", \"response\"])\n",
    "\n",
    "        for i in tqdm(range(0, len(paths), batch_size), desc=f\"GPU{rank}\", unit=\"batch\"):\n",
    "            batch_paths = paths[i:i+batch_size]\n",
    "            batch_pixels = torch.stack([load_image(p, max_num=6) for p in batch_paths])\n",
    "            batch_pixels = batch_pixels.pin_memory().to(torch.bfloat16).cuda(rank, non_blocking=True)\n",
    "\n",
    "            with inference_mode(), autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                try:\n",
    "                    responses = model.chat(tokenizer, batch_pixels, [question] * len(batch_paths), generation_config)\n",
    "                except Exception:\n",
    "                    responses = [model.chat(tokenizer, img, question, generation_config) for img in batch_pixels]\n",
    "\n",
    "            # Write results immediately\n",
    "            for path, resp in zip(batch_paths, responses):\n",
    "                frame_name = os.path.basename(path)\n",
    "                writer.writerow([frame_name, resp])\n",
    "                f.flush()  # ensure it's written to disk right away\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    root_dir = \"/kaggle/input/aic2025/keyframes\"\n",
    "    r0 = pd.read_csv(\"/kaggle/input/tmp-old-inf/old_inference_results_0.csv\")['frame_name']\n",
    "    r1 = pd.read_csv(\"/kaggle/input/tmp-old-inf/old_inference_results_1.csv\")['frame_name']\n",
    "    \n",
    "    partid = 0 # PART here: 0: Dat, 1: Huan, 2: Khoa, 3: Tuan, 4: Phat\n",
    "    \n",
    "    output_csv = \"inference_results.csv\"\n",
    "    batch_size = 4\n",
    "    num_gpus = 2\n",
    "\n",
    "    generation_config = dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=3.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    question = '<image>\\nMô tả chi tiết các vật, màu sắc và chữ trong ảnh.'\n",
    "\n",
    "    image_paths = sorted(glob.glob(f\"{root_dir}/**/*.jpg\", recursive=True))\n",
    "    print(f\"Found {len(image_paths)} images.\")\n",
    "    \n",
    "    existed_results = set(r0).intersection(set(r1))\n",
    "\n",
    "    image_paths = [p for p in image_paths if os.path.splitext(os.path.basename(p))[0] not in existed_results]\n",
    "\n",
    "    print(f\"Remaining {len(image_paths)} images.\")\n",
    "    \n",
    "    def split_list(lst, n_parts=5):\n",
    "        k, m = divmod(len(lst), n_parts)  # k = base size, m = remainder\n",
    "        return [lst[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n_parts)]\n",
    "\n",
    "    image_paths = split_list(image_paths, n_parts=5)[partid]\n",
    "\n",
    "    print(f\"Your part: {len(image_paths)} images.\")\n",
    "\n",
    "    chunks = [image_paths[i::num_gpus] for i in range(num_gpus)]\n",
    "    mp.spawn(workers, args=(chunks, batch_size, question, generation_config), nprocs=num_gpus)\n",
    "\n",
    "    # Merge CSV files\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"frame_name\", \"response\"])\n",
    "        for rank in range(num_gpus):\n",
    "            with open(f\"inference_results_{rank}.csv\", \"r\", encoding=\"utf-8\") as infile:\n",
    "                next(infile)  # skip header\n",
    "                for line in infile:\n",
    "                    outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-15T17:13:59.507251Z",
     "iopub.status.busy": "2025-08-15T17:13:59.507012Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python /kaggle/working/infer.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8073301,
     "sourceId": 12770694,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
